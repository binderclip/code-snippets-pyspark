{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hello_pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binderclip/code-snippets-pyspark/blob/master/notebooks/hello_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhw1Ty5sjV3L",
        "colab_type": "text"
      },
      "source": [
        "refs\n",
        "- [Apache Spark(PySpark) in Google Collaboratory In 3 steps.](https://medium.com/@sushantgautam_930/apache-spark-in-google-collaboratory-in-3-steps-e0acbba654e6)\n",
        "  - [Spark_on_Colaboratory_temp.ipynb - Colaboratory](https://colab.research.google.com/drive/121JqpTvwDEjVjHHECqg_kyCA3j04AScb)\n",
        "- [PySpark in Google Colab - Towards Data Science](https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V7NnTcFiNS0",
        "colab_type": "text"
      },
      "source": [
        "初始化环境"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZGtmuAkiLCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d57ea75a-c746-4cce-965a-145496e9b4a1"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install py4j"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: py4j in /usr/local/lib/python3.6/dist-packages (0.10.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsaq8EpaiTvE",
        "colab_type": "text"
      },
      "source": [
        "设置环境变量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA5opkLmiZj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXj6eWwvibvc",
        "colab_type": "text"
      },
      "source": [
        "创建 spark session 和 spark context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsd_TjeyimiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-2.4.4-bin-hadoop2.7\")# SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP-sRjtKi0j4",
        "colab_type": "text"
      },
      "source": [
        "spark context word count demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZoOoXw7i3F3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "670b212f-a5d2-4a74-fd9f-bd2f6f9da8e2"
      },
      "source": [
        "rdd = sc.parallelize([\"Hello Spark\"])\n",
        "counts = rdd.flatMap(lambda line: line.split(\" \")) \\\n",
        "    .map(lambda word: (word, 1)) \\\n",
        "    .reduceByKey(lambda a, b: a + b) \\\n",
        "    .collect()\n",
        "print(counts)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Hello', 1), ('Spark', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr-ppJjtjJu8",
        "colab_type": "text"
      },
      "source": [
        "create data frame demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbuPfFGijNZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "b7637142-f19a-4d4e-d833-e84c5eca83ba"
      },
      "source": [
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
            "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTg4IIwpjSUr",
        "colab_type": "text"
      },
      "source": [
        "use sample data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBFOCA1djTi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}